import React, { useEffect, useState, useRef } from 'react';
import { 
  View, 
  Text, 
  StyleSheet, 
  Pressable, 
  Alert, 
  Dimensions, 
  Modal,
  ActivityIndicator,
  Vibration 
} from 'react-native';
import { Audio } from 'expo-av';
import * as Speech from 'expo-speech';
import * as Haptics from 'expo-haptics';
import * as Animatable from 'react-native-animatable';
import { BlurView } from 'expo-blur';
import { LinearGradient } from 'expo-linear-gradient';

import { enhancedGeminiVoiceAssistant as geminiVoiceAssistant, VOICE_TOPICS } from '../services/enhancedGeminiVoiceAssistant';
import { speechToText, STT_PROVIDERS } from '../services/speechToText';
import { useAuth } from '../providers/AuthProvider';
import GradientBackground from '../components/GradientBackground';
import VoiceVisualizer from '../components/VoiceVisualizer';
import AnimatedDidiAvatar from '../components/AnimatedDidiAvatar';
import { COLORS, TYPOGRAPHY, SPACING, BORDER_RADIUS } from '../config/theme';

const { width, height } = Dimensions.get('window');

// Call status constants
const CALL_STATUS = {
  CONNECTING: 'connecting',
  CONNECTED: 'connected',
  LISTENING: 'listening',
  PROCESSING: 'processing',
  SPEAKING: 'speaking',
  ENDED: 'ended'
};

export default function ImprovedGeminiVoiceCallScreen({ route, navigation }) {
  const { topic = VOICE_TOPICS.GENERAL_HEALTH } = route.params || {};
  const { profile, updateProfile } = useAuth();
  
  // Call state
  const [callStatus, setCallStatus] = useState(CALL_STATUS.CONNECTING);
  const [callDuration, setCallDuration] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [recording, setRecording] = useState(null);
  const [isProcessing, setIsProcessing] = useState(false);
  const [voiceIntensity, setVoiceIntensity] = useState(0);
  const [showEndModal, setShowEndModal] = useState(false);
  
  // Conversation state
  const [conversationLog, setConversationLog] = useState([]);
  const [currentMessage, setCurrentMessage] = useState('');
  const [avatarEmotion, setAvatarEmotion] = useState('welcoming');
  const [sttProvider, setSttProvider] = useState(STT_PROVIDERS.MOCK);
  const [aiStatus, setAiStatus] = useState('ready'); // ready, processing, responding
  
  // Refs
  const callStartTime = useRef(Date.now());
  const intensityInterval = useRef(null);
  const callTimer = useRef(null);

  useEffect(() => {
    initializeCall();
    startCallTimer();
    
    return () => {
      cleanup();
    };
  }, []);

  const initializeCall = async () => {
    try {
      // Set user profile in voice assistant
      geminiVoiceAssistant.setUserProfile(profile);
      
      // Use Demo STT for presentation
      const hasGeminiKey = !!process.env.EXPO_PUBLIC_GEMINI_API_KEY;
      
      setSttProvider(STT_PROVIDERS.DEMO);
      console.log('üéØ Demo Mode - Interactive voice chat ready!');
      
      if (!hasGeminiKey) {
        console.warn('Gemini API key not configured - AI responses will use fallbacks');
      }
      
      // Start conversation with selected topic
      const initialResponse = await geminiVoiceAssistant.startConversation(topic);
      
      // Add to conversation log
      setConversationLog([{
        role: 'assistant',
        content: initialResponse.text,
        timestamp: Date.now(),
        isRealAI: !initialResponse.isFallback
      }]);
      
      // Simulate connection delay
      setTimeout(() => {
        setCallStatus(CALL_STATUS.CONNECTED);
        speakMessage(initialResponse.text, 'welcoming');
      }, 2000);
      
    } catch (error) {
      console.error('Error initializing call:', error);
      Alert.alert('‡§ï‡•â‡§≤ ‡§ï‡§®‡•á‡§ï‡•çÔøΩÔøΩÔøΩ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§∏‡§ï‡§æ', '‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§');
      navigation.goBack();
    }
  };

  const startCallTimer = () => {
    callTimer.current = setInterval(() => {
      if (callStatus !== CALL_STATUS.ENDED) {
        setCallDuration(Math.floor((Date.now() - callStartTime.current) / 1000));
      }
    }, 1000);
  };

  const cleanup = () => {
    if (recording) {
      recording.stopAndUnloadAsync();
    }
    if (intensityInterval.current) {
      clearInterval(intensityInterval.current);
    }
    if (callTimer.current) {
      clearInterval(callTimer.current);
    }
    Speech.stop();
    geminiVoiceAssistant.clearConversation();
  };

  const speakMessage = async (text, emotion = 'neutral') => {
    try {
      setCallStatus(CALL_STATUS.SPEAKING);
      setAvatarEmotion(emotion);
      setCurrentMessage(text);
      setAiStatus('responding');
      
      // Start voice visualization
      startVoiceVisualization();
      
      Speech.speak(text, {
        language: profile?.language || 'hi-IN',
        rate: 0.8,
        pitch: 1.1,
        onStart: () => {
          setCallStatus(CALL_STATUS.SPEAKING);
        },
        onDone: () => {
          setCallStatus(CALL_STATUS.CONNECTED);
          setVoiceIntensity(0);
          setAvatarEmotion('neutral');
          setAiStatus('ready');
          if (intensityInterval.current) {
            clearInterval(intensityInterval.current);
          }
        },
        onError: () => {
          setCallStatus(CALL_STATUS.CONNECTED);
          setVoiceIntensity(0);
          setAiStatus('ready');
        }
      });
    } catch (error) {
      console.error('Speech error:', error);
      setCallStatus(CALL_STATUS.CONNECTED);
      setAiStatus('ready');
    }
  };

  const startVoiceVisualization = () => {
    if (intensityInterval.current) {
      clearInterval(intensityInterval.current);
    }
    
    intensityInterval.current = setInterval(() => {
      setVoiceIntensity(Math.random() * 0.8 + 0.2);
    }, 150);
  };

  const startRecording = async () => {
    try {
      if (callStatus === CALL_STATUS.SPEAKING) {
        // Stop current speech
        Speech.stop();
      }
      
      setIsRecording(true);
      setCallStatus(CALL_STATUS.LISTENING);
      Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Light);
      Vibration.vibrate(100);
      
      const permission = await Audio.requestPermissionsAsync();
      if (!permission.granted) {
        Alert.alert(
          '‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡•ã‡§® ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§ö‡§æ‡§π‡§ø‡§è',
          '‡§¶‡•Ä‡§¶‡•Ä ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡•ã‡§® ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§Ç‡•§'
        );
        setIsRecording(false);
        setCallStatus(CALL_STATUS.CONNECTED);
        return;
      }

      await Audio.setAudioModeAsync({ 
        allowsRecordingIOS: true, 
        playsInSilentModeIOS: true,
        shouldDuckAndroid: true,
        playThroughEarpieceAndroid: false,
      });

      const rec = new Audio.Recording();
      await rec.prepareToRecordAsync({
        ...Audio.RecordingOptionsPresets.HIGH_QUALITY,
        android: {
          extension: '.m4a',
          outputFormat: Audio.RECORDING_OPTION_ANDROID_OUTPUT_FORMAT_MPEG_4,
          audioEncoder: Audio.RECORDING_OPTION_ANDROID_AUDIO_ENCODER_AAC,
          sampleRate: 44100,
          numberOfChannels: 2,
          bitRate: 128000,
        },
        ios: {
          extension: '.m4a',
          outputFormat: Audio.RECORDING_OPTION_IOS_OUTPUT_FORMAT_MPEG4AAC,
          audioQuality: Audio.RECORDING_OPTION_IOS_AUDIO_QUALITY_HIGH,
          sampleRate: 44100,
          numberOfChannels: 2,
          bitRate: 128000,
        },
      });

      await rec.startAsync();
      setRecording(rec);
      
      // Start recording visualization
      startVoiceVisualization();
      
    } catch (error) {
      console.error('Recording error:', error);
      setIsRecording(false);
      setCallStatus(CALL_STATUS.CONNECTED);
      Alert.alert('‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ', '‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§');
    }
  };

  const stopRecording = async () => {
    try {
      setIsProcessing(true);
      setCallStatus(CALL_STATUS.PROCESSING);
      Haptics.impactAsync(Haptics.ImpactFeedbackStyle.Medium);
      
      if (recording) {
        await recording.stopAndUnloadAsync();
        const uri = recording.getURI();
        setRecording(null);
        setIsRecording(false);
        setVoiceIntensity(0);
        
        if (intensityInterval.current) {
          clearInterval(intensityInterval.current);
        }
        
        await processUserAudio(uri);
      }
    } catch (error) {
      console.error('Stop recording error:', error);
      setIsRecording(false);
      setIsProcessing(false);
      setCallStatus(CALL_STATUS.CONNECTED);
    }
  };

  const processUserAudio = async (audioUri) => {
    try {
      setAiStatus('processing');
      
      // Use real speech-to-text with intelligent fallback
      const sttResult = await speechToText(audioUri, {
        language: profile?.language || 'hi-IN',
        provider: sttProvider,
        context: topic,
        maxRetries: 2
      });
      
      let userMessage;
      let sttSuccess = false;
      
      if (sttResult.success && sttResult.text.trim().length > 0) {
        userMessage = sttResult.text;
        sttSuccess = true;
      } else {
        // Fallback to contextual mock response
        userMessage = generateContextualUserMessage();
        console.warn('STT failed or empty, using mock response:', sttResult.error);
      }
      
      // Add user message to log
      const userLogEntry = {
        role: 'user',
        content: userMessage,
        timestamp: Date.now(),
        audioUri,
        sttConfidence: sttResult.confidence || 0.8,
        sttProvider: sttResult.provider || 'mock',
        sttSuccess
      };
      setConversationLog(prev => [...prev, userLogEntry]);
      
      // Get AI response from Gemini
      const aiResponse = await geminiVoiceAssistant.sendMessage(userMessage);
      
      // Add AI response to log
      const aiLogEntry = {
        role: 'assistant',
        content: aiResponse.text,
        timestamp: Date.now(),
        isRealAI: !aiResponse.isFallback,
        topic: aiResponse.topic
      };
      setConversationLog(prev => [...prev, aiLogEntry]);
      
      // Determine emotion from response
      const emotion = determineEmotionFromText(aiResponse.text);
      
      // Speak the response
      await speakMessage(aiResponse.text, emotion);
      
      // Save conversation progress
      await saveConversationProgress(userMessage, aiResponse.text, sttSuccess);
      
      // Check if call should end
      if (aiResponse.endCall) {
        setTimeout(() => {
          endCall();
        }, 2000);
      }
      
    } catch (error) {
      console.error('Process audio error:', error);
      const fallbackMessage = '‡§Æ‡•Å‡§ù‡•á ‡§∏‡§Æ‡§ù‡§®‡•á ‡§Æ‡•á‡§Ç ‡§•‡•ã‡§°‡§º‡•Ä ‡§¶‡•á‡§∞ ‡§≤‡§ó‡•Ä‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§´‡§ø‡§∞ ‡§∏‡•á ‡§ï‡§π‡•á‡§Ç‡•§';
      await speakMessage(fallbackMessage, 'concerned');
    } finally {
      setIsProcessing(false);
      setCallStatus(CALL_STATUS.CONNECTED);
      setAiStatus('ready');
    }
  };

  const generateContextualUserMessage = () => {
    const topicResponses = {
      menstrual_health: [
        '‡§Æ‡§π‡§æ‡§µ‡§æ‡§∞‡•Ä ‡§ï‡•á ‡§¶‡•å‡§∞‡§æ‡§® ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?',
        '‡§¶‡§∞‡•ç‡§¶ ‡§∏‡•á ‡§ï‡•à‡§∏‡•á ‡§∞‡§æ‡§π‡§§ ‡§Æ‡§ø‡§≤‡•á‡§ó‡•Ä?',
        '‡§ï‡§ø‡§§‡§®‡•á ‡§¶‡§ø‡§® ‡§§‡§ï ‡§π‡•ã‡§§‡•Ä ‡§π‡•à?',
        '‡§ï‡•ç‡§Ø‡§æ ‡§Ø‡§π ‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§π?'
      ],
      pregnancy_care: [
        '‡§ó‡§∞‡•ç‡§≠‡§æ‡§µ‡§∏‡•ç‡§•‡§æ ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ñ‡§æ‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?',
        '‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§ï‡§¨ ‡§Æ‡§ø‡§≤‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?',
        '‡§Æ‡•Å‡§ù‡•á ‡§â‡§≤‡•ç‡§ü‡•Ä ‡§Ü‡§§‡•Ä ‡§π‡•à',
        '‡§¨‡§ö‡•ç‡§ö‡•á ‡§ï‡•Ä ‡§π‡§≤‡§ö‡§≤ ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•ã ‡§∞‡§π‡•Ä',
        '‡§ï‡•ç‡§Ø‡§æ ‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•Ä ‡§π‡•Ç‡§Ç?',
        '‡§™‡•ç‡§∞‡§∏‡§µ ‡§ï‡•Ä ‡§§‡•à‡§Ø‡§æ‡§∞‡•Ä ‡§ï‡•à‡§∏‡•á ‡§ï‡§∞‡•Ç‡§Ç?',
        '‡§µ‡§ú‡§® ‡§ï‡§ø‡§§‡§®‡§æ ‡§¨‡§¢‡§º‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?',
        '‡§ï‡•å‡§® ‡§∏‡•á ‡§ü‡•á‡§∏‡•ç‡§ü ‡§ï‡§∞‡§æ‡§®‡•á ‡§ö‡§æ‡§π‡§ø‡§è?'
      ],
      [VOICE_TOPICS.DIGITAL_LITERACY]: [
        '‡§´‡•ã‡§® ‡§ï‡•à‡§∏‡•á ‡§ö‡§≤‡§æ‡§§‡•á ‡§π‡•à‡§Ç?',
        'UPI ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?',
        '‡§™‡•à‡§∏‡•á ‡§ï‡•à‡§∏‡•á ‡§≠‡•á‡§ú‡§§‡•á ‡§π‡•à‡§Ç?',
        'WhatsApp ‡§ï‡•à‡§∏‡•á ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§∞‡•Ç‡§Ç?',
        '‡§á‡§Ç‡§ü‡§∞‡§®‡•á‡§ü ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§∏‡§æ‡§µ‡§ß‡§æ‡§®‡•Ä ‡§∞‡§ñ‡•Ç‡§Ç?',
        'QR ‡§ï‡•ã‡§° ‡§ï‡•à‡§∏‡•á ‡§∏‡•ç‡§ï‡•à‡§® ‡§ï‡§∞‡•Ç‡§Ç?',
        '‡§ë‡§®‡§≤‡§æ‡§á‡§® ‡§´‡•ç‡§∞‡•â‡§° ‡§∏‡•á ‡§ï‡•à‡§∏‡•á ‡§¨‡§ö‡•Ç‡§Ç?',
        '‡§°‡§øÔøΩÔøΩÔøΩ‡§ø‡§ü‡§≤ ‡§™‡•á‡§Æ‡•á‡§Ç‡§ü ‡§∏‡•Å‡§∞‡§ï‡•ç‡§∑‡§ø‡§§ ‡§π‡•à?'
      ],
      [VOICE_TOPICS.GENERAL_HEALTH]: [
        '‡§∏‡•á‡§π‡§§ ‡§ï‡•à‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§∞‡§ñ‡•Ç‡§Ç?',
        '‡§¨‡§ö‡•ç‡§ö‡•ã‡§Ç ‡§ï‡§æ ‡§ü‡•Ä‡§ï‡§æ‡§ï‡§∞‡§£ ‡§ï‡§¨ ‡§ï‡§∞‡§æ‡§è‡§Ç?',
        '‡§ñ‡§æ‡§®‡•á ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡•Ç‡§Ç?',
        '‡§∏‡§´‡§æ‡§à ‡§ï‡•à‡§∏‡•á ‡§∞‡§ñ‡•Ç‡§Ç?',
        '‡§¨‡•Å‡§ñ‡§æ‡§∞ ‡§Ü‡§è ‡§§‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡§∞‡•Ç‡§Ç?',
        '‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§∏‡•á ‡§ï‡§¨ ‡§Æ‡§ø‡§≤‡•Ç‡§Ç?',
        '‡§™‡§æ‡§®‡•Ä ‡§ï‡§ø‡§§‡§®‡§æ ‡§™‡•Ä‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?',
        '‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§ï‡•à‡§∏‡•á ‡§ï‡§∞‡•Ç‡§Ç?'
      ]
    };
    
    const responses = topicResponses[topic] || topicResponses[VOICE_TOPICS.GENERAL_HEALTH];
    return responses[Math.floor(Math.random() * responses.length)];
  };

  const determineEmotionFromText = (text) => {
    const lowerText = text.toLowerCase();
    if (lowerText.includes('‡§∂‡§æ‡§¨‡§æ‡§∂') || lowerText.includes('‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡§æ') || lowerText.includes('‡§¨‡§ß‡§æ‡§à')) {
      return 'proud';
    } else if (lowerText.includes('‡§ö‡§ø‡§Ç‡§§‡§æ') || lowerText.includes('‡§∏‡§Æ‡§∏‡•ç‡§Ø‡§æ') || lowerText.includes('‡§°‡•â‡§ï‡•ç‡§ü‡§∞')) {
      return 'concerned';
    } else if (lowerText.includes('‡§ñ‡•Å‡§∂') || lowerText.includes('‡§Ö‡§ö‡•ç‡§õ‡§æ ÔøΩÔøΩÔøΩ‡§ó‡§æ')) {
      return 'happy';
    } else if (lowerText.includes('‡§π‡§ø‡§Æ‡•ç‡§Æ‡§§') || lowerText.includes('‡§ï‡•ã‡§∂‡§ø‡§∂') || lowerText.includes('‡§∏‡•Ä‡§ñ‡§®‡§æ')) {
      return 'encouraging';
    }
    return 'neutral';
  };

  const saveConversationProgress = async (userMessage, aiResponse, sttSuccess) => {
    try {
      const conversationData = {
        topic,
        userMessage,
        aiResponse,
        timestamp: Date.now(),
        callDuration,
        sttSuccess,
        sttProvider
      };
      
      // Update user profile with conversation progress
      const updatedProfile = {
        ...profile,
        voiceCallProgress: {
          ...profile?.voiceCallProgress,
          [topic]: {
            ...profile?.voiceCallProgress?.[topic],
            totalCalls: (profile?.voiceCallProgress?.[topic]?.totalCalls || 0) + 1,
            totalDuration: (profile?.voiceCallProgress?.[topic]?.totalDuration || 0) + callDuration,
            lastCall: Date.now(),
            sttSuccessRate: calculateSTTSuccessRate(profile?.voiceCallProgress?.[topic], sttSuccess),
            conversations: [
              ...(profile?.voiceCallProgress?.[topic]?.conversations || []).slice(-9), // Keep last 10
              conversationData
            ]
          }
        }
      };
      
      await updateProfile(updatedProfile);
    } catch (error) {
      console.error('Error saving conversation progress:', error);
    }
  };

  const calculateSTTSuccessRate = (topicProgress, currentSuccess) => {
    const previousRate = topicProgress?.sttSuccessRate || 0.8;
    const totalCalls = topicProgress?.totalCalls || 0;
    
    if (totalCalls === 0) return currentSuccess ? 1.0 : 0.0;
    
    // Weighted average with current success
    return (previousRate * totalCalls + (currentSuccess ? 1 : 0)) / (totalCalls + 1);
  };

  const endCall = () => {
    setCallStatus(CALL_STATUS.ENDED);
    Speech.stop();
    Haptics.notificationAsync(Haptics.NotificationFeedbackType.Success);
    setShowEndModal(true);
  };

  const formatDuration = (seconds) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  const getTopicTitle = () => {
    const titles = {
      [VOICE_TOPICS.MENSTRUAL_HEALTH]: '‡§Æ‡§π‡§æ‡§µ‡§æ‡§∞‡•Ä ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä',
      [VOICE_TOPICS.PREGNANCY_CARE]: '‡§ó‡§∞‡•ç‡§≠‡§æ‡§µ‡§∏‡•ç‡§•‡§æ ‡§ï‡•Ä ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤',
      [VOICE_TOPICS.DIGITAL_LITERACY]: '‡§°‡§ø‡§ú‡§ø‡§ü‡§≤ ‡§∏‡§æ‡§ï‡•ç‡§∑‡§∞‡§§‡§æ',
      [VOICE_TOPICS.GENERAL_HEALTH]: '‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø'
    };
    return titles[topic] || '‡§¶‡•Ä‡§¶‡•Ä ‡§∏‡•á ‡§¨‡§æ‡§§';
  };

  const getSTTProviderName = () => {
    const names = {
      [STT_PROVIDERS.GOOGLE]: 'Google',
      [STT_PROVIDERS.AZURE]: 'Azure',
      [STT_PROVIDERS.MOCK]: 'Demo'
    };
    return names[sttProvider] || 'Unknown';
  };

  const renderCallHeader = () => (
    <Animatable.View animation="fadeInDown" style={styles.callHeader}>
      <View style={styles.callInfo}>
        <Text style={styles.topicTitle}>{getTopicTitle()}</Text>
        <Text style={styles.callStatusText}>
          {callStatus === CALL_STATUS.CONNECTING && 'üìû ‡§ï‡§®‡•á‡§ï‡•ç‡§ü ‡§π‡•ã ‡§∞‡§π‡§æ ‡§π‡•à...'}
          {callStatus === CALL_STATUS.CONNECTED && 'üí¨ ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ö‡§æ‡§≤‡•Ç'}
          {callStatus === CALL_STATUS.LISTENING && 'üé§ ‡§∏‡•Å‡§® ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Ç...'}
          {callStatus === CALL_STATUS.PROCESSING && 'üß† ‡§∏‡§Æ‡§ù ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Ç...'}
          {callStatus === CALL_STATUS.SPEAKING && 'üó£Ô∏è ‡§¶‡•Ä‡§¶‡•Ä ‡§¨‡•ã‡§≤ ‡§∞‡§π‡•Ä ‡§π‡•à‡§Ç...'}
        </Text>
        <Text style={styles.callDuration}>{formatDuration(callDuration)}</Text>
        
        {/* STT Provider Indicator */}
        <View style={styles.providerIndicator}>
          <Text style={styles.providerText}>
            {getSTTProviderName()} STT ‚Ä¢ {aiStatus === 'ready' ? 'üü¢' : 'üü°'} AI
          </Text>
        </View>
      </View>
    </Animatable.View>
  );

  const renderDidiAvatar = () => (
    <Animatable.View animation="zoomIn" delay={300} style={styles.avatarSection}>
      <View style={styles.avatarContainer}>
        <AnimatedDidiAvatar
          isListening={isRecording}
          isSpeaking={callStatus === CALL_STATUS.SPEAKING}
          isThinking={callStatus === CALL_STATUS.PROCESSING}
          emotion={avatarEmotion}
          size={180}
        />
        
        {/* Voice Visualizer */}
        <View style={styles.voiceVisualizerContainer}>
          <VoiceVisualizer 
            isActive={isRecording || callStatus === CALL_STATUS.SPEAKING} 
            intensity={voiceIntensity}
            color={isRecording ? COLORS.status.error : COLORS.primary[400]}
          />
        </View>
      </View>
      
      <Text style={styles.didiName}>‡§¶‡•Ä‡§¶‡•Ä</Text>
      <Text style={styles.didiStatus}>
        {callStatus === CALL_STATUS.CONNECTING && '‡§ï‡§®‡•á‡§ï‡•ç‡§ü ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Ç...'}
        {callStatus === CALL_STATUS.CONNECTED && '‡§Ü‡§™‡§ï‡§æ ‡§á‡§Ç‡§§‡§ú‡§º‡§æ‡§∞ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Ç'}
        {callStatus === CALL_STATUS.LISTENING && '‡§Ü‡§™‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§∏‡•Å‡§® ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Ç...'}
        {callStatus === CALL_STATUS.PROCESSING && '‡§Ü‡§™‡§ï‡•Ä ‡§¨‡§æ‡§§ ‡§∏‡§Æ‡§ù ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Ç...'}
        {callStatus === CALL_STATUS.SPEAKING && '‡§Ü‡§™‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Ç...'}
      </Text>
      
      {/* Current Message Display */}
      {currentMessage && callStatus === CALL_STATUS.SPEAKING && (
        <View style={styles.messageContainer}>
          <Text style={styles.currentMessage}>{currentMessage}</Text>
        </View>
      )}
    </Animatable.View>
  );

  const renderCallControls = () => (
    <Animatable.View animation="fadeInUp" delay={500} style={styles.controlsSection}>
      {/* Main Call Button */}
      <View style={styles.mainControlContainer}>
        {!isRecording ? (
          <Pressable 
            style={[
              styles.callButton, 
              styles.micButton,
              (callStatus === CALL_STATUS.CONNECTING || isProcessing) && styles.disabledButton
            ]} 
            onPress={startRecording}
            disabled={callStatus === CALL_STATUS.CONNECTING || isProcessing}
          >
            <LinearGradient
              colors={isProcessing ? ['#ccc', '#999'] : ['#10B981', '#34D399']}
              style={styles.callButtonGradient}
            >
              {isProcessing ? (
                <>
                  <ActivityIndicator size="large" color="#fff" />
                  <Text style={styles.callButtonText}>
                    {callStatus === CALL_STATUS.PROCESSING ? '‡§∏‡§Æ‡§ù ‡§∞‡§π‡•Ä ‡§π‡•Ç‡§Ç...' : '‡§™‡•ç‡§∞‡•ã‡§∏‡•á‡§∏‡§ø‡§Ç‡§ó...'}
                  </Text>
                </>
              ) : (
                <>
                  <Text style={styles.callButtonIcon}>üé§</Text>
                  <Text style={styles.callButtonText}>
                    {callStatus === CALL_STATUS.CONNECTING ? '‡§ï‡§®‡•á‡§ï‡•ç‡§ü ‡§π‡•ã ‡§∞‡§π‡§æ...' : '‡§¨‡•ã‡§≤‡•á‡§Ç'}
                  </Text>
                </>
              )}
            </LinearGradient>
          </Pressable>
        ) : (
          <Pressable 
            style={[styles.callButton, styles.stopButton]} 
            onPress={stopRecording}
          >
            <LinearGradient
              colors={['#EF4444', '#DC2626']}
              style={styles.callButtonGradient}
            >
              <Text style={styles.callButtonIcon}>‚èπÔ∏è</Text>
              <Text style={styles.callButtonText}>‡§∞‡•ã‡§ï‡•á‡§Ç</Text>
            </LinearGradient>
          </Pressable>
        )}
      </View>
      
      {/* Secondary Controls */}
      <View style={styles.secondaryControls}>
        <Pressable 
          style={styles.secondaryButton}
          onPress={() => Speech.stop()}
        >
          <Text style={styles.secondaryButtonIcon}>üîá</Text>
          <Text style={styles.secondaryButtonText}>ÔøΩÔøΩÔøΩ‡•Å‡§™</Text>
        </Pressable>
        
        <Pressable 
          style={[styles.secondaryButton, styles.endCallButton]}
          onPress={endCall}
        >
          <Text style={styles.secondaryButtonIcon}>üìû</Text>
          <Text style={styles.secondaryButtonText}>‡§∏‡§Æ‡§æ‡§™‡•ç‡§§</Text>
        </Pressable>
      </View>
    </Animatable.View>
  );

  const renderEndCallModal = () => {
    const realAIMessages = conversationLog.filter(msg => msg.role === 'assistant' && msg.isRealAI).length;
    const sttSuccessCount = conversationLog.filter(msg => msg.role === 'user' && msg.sttSuccess).length;
    const totalUserMessages = conversationLog.filter(msg => msg.role === 'user').length;
    
    return (
      <Modal transparent visible={showEndModal} animationType="fade">
        <BlurView intensity={80} style={styles.modalOverlay}>
          <Animatable.View animation="bounceIn" style={styles.endCallModal}>
            <Text style={styles.modalIcon}>üéâ</Text>
            <Text style={styles.modalTitle}>
              ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§π‡•Å‡§à!
            </Text>
            <Text style={styles.modalSubtitle}>
              ‡§Ü‡§™‡§®‡•á ‡§¶‡•Ä‡§¶‡•Ä ‡§∏‡•á {formatDuration(callDuration)} ‡§§‡§ï ‡§¨‡§æ‡§§ ‡§ï‡•Ä
            </Text>
            
            <View style={styles.callSummary}>
              <View style={styles.summaryItem}>
                <Text style={styles.summaryNumber}>{conversationLog.length}</Text>
                <Text style={styles.summaryLabel}>‡§∏‡§Ç‡§¶‡•á‡§∂</Text>
              </View>
              <View style={styles.summaryItem}>
                <Text style={styles.summaryNumber}>{realAIMessages}</Text>
                <Text style={styles.summaryLabel}>AI ‡§ú‡§µ‡§æ‡§¨</Text>
              </View>
              <View style={styles.summaryItem}>
                <Text style={styles.summaryNumber}>
                  {totalUserMessages > 0 ? Math.round((sttSuccessCount / totalUserMessages) * 100) : 0}%
                </Text>
                <Text style={styles.summaryLabel}>STT ‡§∏‡§´‡§≤‡§§‡§æ</Text>
              </View>
            </View>
            
            <Text style={styles.modalMessage}>
              ‡§Ü‡§ú ‡§Ü‡§™‡§®‡•á ‡§¨‡§π‡•Å‡§§ ‡§ï‡•Å‡§õ ‡§∏‡•Ä‡§ñ‡§æ‡•§ {getSTTProviderName()} STT ‡§î‡§∞ Gemini AI ‡§ï‡•á ‡§∏‡§æ‡§• ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§π‡•Å‡§à‡•§ ‡§ï‡§≤ ‡§´‡§ø‡§∞ ‡§¶‡•Ä‡§¶‡•Ä ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§ø‡§è‡§ó‡§æ!
            </Text>
            
            <View style={styles.modalButtons}>
              <Pressable 
                style={styles.modalButton}
                onPress={() => navigation.replace('SeparateProgress')}
              >
                <Text style={styles.modalButtonText}>‡§™‡•ç‡§∞‡§ó‡§§‡§ø ‡§¶‡•á‡§ñ‡•á‡§Ç</Text>
              </Pressable>
              <Pressable 
                style={[styles.modalButton, styles.primaryModalButton]}
                onPress={() => navigation.replace('Home')}
              >
                <Text style={[styles.modalButtonText, styles.primaryModalButtonText]}>
                  ‡§π‡•ã‡§Æ ‡§ú‡§æ‡§è‡§Ç
                </Text>
              </Pressable>
            </View>
          </Animatable.View>
        </BlurView>
      </Modal>
    );
  };

  return (
    <GradientBackground colors={['#8B7355', '#A67C52']}>
      <View style={styles.container}>
        {renderCallHeader()}
        {renderDidiAvatar()}
        {renderCallControls()}
        {renderEndCallModal()}
      </View>
    </GradientBackground>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    padding: SPACING.lg,
  },
  callHeader: {
    alignItems: 'center',
    marginTop: SPACING.xl,
    marginBottom: SPACING.lg,
  },
  callInfo: {
    alignItems: 'center',
    backgroundColor: 'rgba(255, 255, 255, 0.1)',
    borderRadius: BORDER_RADIUS.lg,
    padding: SPACING.lg,
    minWidth: width * 0.8,
  },
  topicTitle: {
    fontSize: TYPOGRAPHY.fontSize.xl,
    fontWeight: TYPOGRAPHY.fontWeight.bold,
    color: COLORS.neutral.white,
    marginBottom: SPACING.xs,
    textAlign: 'center',
  },
  callStatusText: {
    fontSize: TYPOGRAPHY.fontSize.base,
    color: 'rgba(255, 255, 255, 0.9)',
    marginBottom: SPACING.xs,
  },
  callDuration: {
    fontSize: TYPOGRAPHY.fontSize.lg,
    color: COLORS.primary[300],
    fontWeight: TYPOGRAPHY.fontWeight.bold,
    marginBottom: SPACING.xs,
  },
  providerIndicator: {
    backgroundColor: 'rgba(255, 255, 255, 0.2)',
    borderRadius: BORDER_RADIUS.full,
    paddingHorizontal: SPACING.md,
    paddingVertical: SPACING.xs,
  },
  providerText: {
    fontSize: TYPOGRAPHY.fontSize.sm,
    color: 'rgba(255, 255, 255, 0.8)',
    fontWeight: TYPOGRAPHY.fontWeight.medium,
  },
  avatarSection: {
    flex: 1,
    alignItems: 'center',
    justifyContent: 'center',
  },
  avatarContainer: {
    position: 'relative',
    marginBottom: SPACING.lg,
  },
  voiceVisualizerContainer: {
    position: 'absolute',
    top: -30,
    left: -30,
    right: -30,
    bottom: -30,
  },
  didiName: {
    fontSize: TYPOGRAPHY.fontSize.xl,
    fontWeight: TYPOGRAPHY.fontWeight.bold,
    color: COLORS.neutral.white,
    marginBottom: SPACING.sm,
  },
  didiStatus: {
    fontSize: TYPOGRAPHY.fontSize.base,
    color: 'rgba(255, 255, 255, 0.8)',
    textAlign: 'center',
    marginBottom: SPACING.lg,
  },
  messageContainer: {
    backgroundColor: 'rgba(255, 255, 255, 0.1)',
    borderRadius: BORDER_RADIUS.lg,
    padding: SPACING.md,
    maxWidth: width * 0.8,
    marginTop: SPACING.md,
  },
  currentMessage: {
    color: COLORS.neutral.white,
    fontSize: TYPOGRAPHY.fontSize.base,
    textAlign: 'center',
    lineHeight: 22,
  },
  controlsSection: {
    alignItems: 'center',
    marginBottom: SPACING.xl,
  },
  mainControlContainer: {
    marginBottom: SPACING.lg,
  },
  callButton: {
    borderRadius: BORDER_RADIUS.full,
    elevation: 8,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 4 },
    shadowOpacity: 0.3,
    shadowRadius: 8,
  },
  callButtonGradient: {
    paddingVertical: SPACING.xl,
    paddingHorizontal: SPACING.xl,
    alignItems: 'center',
    justifyContent: 'center',
    minWidth: 160,
    minHeight: 160,
    borderRadius: BORDER_RADIUS.full,
  },
  callButtonIcon: {
    fontSize: 40,
    marginBottom: SPACING.sm,
  },
  callButtonText: {
    color: COLORS.neutral.white,
    fontSize: TYPOGRAPHY.fontSize.lg,
    fontWeight: TYPOGRAPHY.fontWeight.bold,
    textAlign: 'center',
  },
  disabledButton: {
    opacity: 0.6,
  },
  secondaryControls: {
    flexDirection: 'row',
    gap: SPACING.xl,
  },
  secondaryButton: {
    backgroundColor: 'rgba(255, 255, 255, 0.2)',
    borderRadius: BORDER_RADIUS.lg,
    paddingVertical: SPACING.md,
    paddingHorizontal: SPACING.lg,
    alignItems: 'center',
    borderWidth: 1,
    borderColor: 'rgba(255, 255, 255, 0.3)',
    minWidth: 80,
  },
  endCallButton: {
    backgroundColor: 'rgba(239, 68, 68, 0.8)',
  },
  secondaryButtonIcon: {
    fontSize: 24,
    marginBottom: SPACING.xs,
  },
  secondaryButtonText: {
    color: COLORS.neutral.white,
    fontSize: TYPOGRAPHY.fontSize.sm,
    fontWeight: TYPOGRAPHY.fontWeight.semibold,
  },
  modalOverlay: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    padding: SPACING.lg,
  },
  endCallModal: {
    backgroundColor: 'rgba(255, 255, 255, 0.95)',
    borderRadius: BORDER_RADIUS.xl,
    padding: SPACING['2xl'],
    alignItems: 'center',
    width: '100%',
    maxWidth: 350,
  },
  modalIcon: {
    fontSize: 64,
    marginBottom: SPACING.lg,
  },
  modalTitle: {
    fontSize: TYPOGRAPHY.fontSize['2xl'],
    fontWeight: TYPOGRAPHY.fontWeight.bold,
    color: COLORS.text.primary,
    textAlign: 'center',
    marginBottom: SPACING.md,
  },
  modalSubtitle: {
    fontSize: TYPOGRAPHY.fontSize.base,
    color: COLORS.text.secondary,
    textAlign: 'center',
    marginBottom: SPACING.lg,
  },
  callSummary: {
    flexDirection: 'row',
    justifyContent: 'space-around',
    width: '100%',
    marginBottom: SPACING.lg,
  },
  summaryItem: {
    alignItems: 'center',
  },
  summaryNumber: {
    fontSize: TYPOGRAPHY.fontSize.lg,
    fontWeight: TYPOGRAPHY.fontWeight.bold,
    color: COLORS.primary[600],
    marginBottom: SPACING.xs,
  },
  summaryLabel: {
    fontSize: TYPOGRAPHY.fontSize.sm,
    color: COLORS.text.secondary,
    textAlign: 'center',
  },
  modalMessage: {
    fontSize: TYPOGRAPHY.fontSize.base,
    color: COLORS.text.secondary,
    textAlign: 'center',
    lineHeight: 22,
    marginBottom: SPACING.lg,
  },
  modalButtons: {
    flexDirection: 'row',
    gap: SPACING.md,
    width: '100%',
  },
  modalButton: {
    flex: 1,
    paddingVertical: SPACING.md,
    paddingHorizontal: SPACING.lg,
    borderRadius: BORDER_RADIUS.full,
    backgroundColor: COLORS.neutral.gray[200],
    alignItems: 'center',
  },
  primaryModalButton: {
    backgroundColor: COLORS.primary[500],
  },
  modalButtonText: {
    fontSize: TYPOGRAPHY.fontSize.base,
    fontWeight: TYPOGRAPHY.fontWeight.semibold,
    color: COLORS.text.primary,
  },
  primaryModalButtonText: {
    color: COLORS.neutral.white,
  },
});